## 三个步骤
- 数据加载：数据怎么加载，标签怎么定义，用什么数据增强方法，都是这一个步进行
- 模型选择：网络结构自己定义
- 算法选择：选什么 loss，用什么优化算法

## 常见名词
- Sota

State of the arts 的缩写，一般就是指在一些 benchmark 的数据集上跑分非常高的那些模型。

SOTA model: 并不是特指某个具体的模型，而是指在该项研究任务中，目前最好/最先进的模型。

SOTA result: 指的是在该项研究任务中，目前最好的模型的结果/性能/表现。

- 非端到端模型

传统机器学习的流程往往由多个独立的模块组成，比如在一个典型的**自然语言处理**问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，其结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端的。

- 端到端模型

从输入端到输出端会得到一个预测结果，将预测结果和真实结果进行比较的得到误差，将误差反向传播到网络的各个层之中，调整网络的权重和参数知道模型收敛或者达到预期的效果为止，中间所有的操作都包涵在神经网络内部，不再分成多个模块处理。由原始数据输入，到结果输出，从输入端到输出端，中间的神经网络自成一体（也可以当作黑盒子看待），这是端到端的。

- Benchmark Baseline

Benchmark 和 Baseline 都是指最基础的比较对象。你的论文的 motivation 来自于你想超越现有的 benchmark / baseline，你的实验数据都需要以 benchmak / baseline 为基准来判断是否有提高。唯一的区别就是 baseline 讲究一套方法，而 benchmark 更偏向于一个目前最高的指标，例如 precision / recall 等等可量化的指标。举个例子，NLP 任务中 BERT 是目前的 SOTA，你有 idea 可以超越 BERT。那在论文中的实验部分你的方法需要比较的 baseline 就是 BERT，而需要比较的 benchmark 就是 BERT 具体的各项指标。
